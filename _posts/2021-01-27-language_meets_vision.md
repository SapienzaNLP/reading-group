---
layout: post
title: When Language Meets Vision
---
**When**:  Wednesday 27th of January, 09:00 AM

**Topic**: Vision & Language

           
**Speaker**: 
[Bianca Scarlini](https://twitter.com/biancascarlini)

### Abstract
Humans see and make sense of the world through different modalities. They gather information from each of their senses and put them together to have a comprehensive understanding of what is around them. Research tried to mimic this process so as to make neural networks grasp the key concepts needed for a better perception of the world and ground their distributional representations in the real world.  In this brief talk, we are going to guide you through the most recent advances in the multimodal field of NLP. We will focus on vision-and-language pre-training techniques for  Transformer-based models and we will see how these cross-modal representations can be exploited for vision-and-language tasks.

## Material
- [Slides](https://sapienzanlp.github.io/reading-group/material/2021-01-27-language_meets_vision/Multimodal - Reading Group.pdf)
- [Presentation](https://drive.google.com/file/d/1wK0yI7bn8n3EkIMXI6x74IL6SvKWNpcc/view?usp=sharing)